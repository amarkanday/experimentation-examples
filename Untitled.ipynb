{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2470c6ec-e4e5-48be-876c-40723da7005a",
   "metadata": {},
   "source": [
    "# CUPED: Understanding and Implementing Variance Reduction in A/B Testing\n",
    "\n",
    "## 1. Introduction to CUPED\n",
    "\n",
    "CUPED (Controlled-experiment Using Pre-Experiment Data) is a variance reduction technique used to improve the sensitivity of A/B tests. It was first introduced by Microsoft in 2013 and has since become a popular method in the field of online experimentation.\n",
    "\n",
    "The core idea of CUPED is to leverage historical (pre-experiment) data to reduce the noise in experiment metrics, thereby allowing experimenters to:\n",
    "- Detect smaller changes with the same sample size\n",
    "- Maintain the same detection power with smaller sample sizes\n",
    "- Reduce the duration of experiments\n",
    "\n",
    "let us start by importing the necessary libraries:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.power import TTestIndPower\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import warnings\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set styles for visualizations\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"Set2\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display options for pandas\n",
    "pd.set_option('display.max_columns', None)\n",
    "```\n",
    "\n",
    "## 2. Why CUPED is Needed: The Variance Problem in A/B Testing\n",
    "\n",
    "In A/B testing, we're trying to detect a difference in a metric (e.g., revenue per user, conversion rate) between a control group and a treatment group. However, many metrics have high variance, which creates two main problems:\n",
    "\n",
    "1. **Low Statistical Power**: High variance makes it difficult to detect small but meaningful treatment effects\n",
    "2. **Long Experiment Duration**: To compensate for high variance, we need larger sample sizes, which means longer experiment run times\n",
    "\n",
    "Let illustrate this with an example:\n",
    "\n",
    "```python\n",
    "def simulate_user_data(n_users=10000, treatment_effect=0, pre_post_correlation=0.7):\n",
    "    \"\"\"\n",
    "    Simulate user data with pre and post experiment metrics\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    n_users : int\n",
    "        Number of users\n",
    "    treatment_effect : float\n",
    "        The effect size to simulate for the treatment group\n",
    "    pre_post_correlation : float\n",
    "        Correlation between pre and post experiment metrics\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame with user data\n",
    "    \"\"\"\n",
    "    # Create user IDs\n",
    "    user_ids = np.arange(n_users)\n",
    "    \n",
    "    # Assign users to control or treatment (50/50 split)\n",
    "    treatment = np.random.binomial(1, 0.5, n_users)\n",
    "    \n",
    "    # Generate pre-experiment data (e.g., spending in the previous month)\n",
    "    # We'll simulate a right-skewed distribution typical of spending/revenue data\n",
    "    base_spending = np.random.gamma(shape=2, scale=10, size=n_users)\n",
    "    \n",
    "    # Create user-level noise that affects both pre and post measurements\n",
    "    user_noise = np.random.normal(0, 10, n_users)\n",
    "    \n",
    "    # Generate post-experiment data with correlation to pre-experiment data\n",
    "    # and with treatment effect for the treatment group\n",
    "    post_spending = (\n",
    "        base_spending * 1.1 +  # Some natural growth for all users\n",
    "        pre_post_correlation * user_noise +  # Correlated component\n",
    "        np.random.normal(0, 15, n_users) +  # Random noise specific to post period\n",
    "        treatment_effect * treatment  # Treatment effect\n",
    "    )\n",
    "    \n",
    "    # For visualization purposes, let us also generate a random cohort\n",
    "    cohorts = np.random.choice(['New', 'Returning', 'Loyal'], n_users, p=[0.3, 0.5, 0.2])\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'user_id': user_ids,\n",
    "        'treatment': treatment,\n",
    "        'cohort': cohorts,\n",
    "        'pre_metric': base_spending,\n",
    "        'post_metric': post_spending\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Simulate data without treatment effect\n",
    "df = simulate_user_data(n_users=10000, treatment_effect=0)\n",
    "\n",
    "# Display first few rows\n",
    "print(\"Sample of simulated user data:\")\n",
    "df.head()\n",
    "```\n",
    "\n",
    "Now, let us visualize the high variance in our data:\n",
    "\n",
    "```python\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot histograms of post-experiment metrics\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(df[df['treatment'] == 0]['post_metric'], \n",
    "             label='Control', alpha=0.7, kde=True)\n",
    "sns.histplot(df[df['treatment'] == 1]['post_metric'], \n",
    "             label='Treatment', alpha=0.7, kde=True)\n",
    "plt.title('Distribution of Post-Experiment Metric')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "\n",
    "# Plot scatter plot of pre vs post metrics\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.scatterplot(data=df, x='pre_metric', y='post_metric', \n",
    "                hue='treatment', alpha=0.5)\n",
    "plt.title('Pre vs. Post Metric Values')\n",
    "plt.xlabel('Pre-Experiment Metric')\n",
    "plt.ylabel('Post-Experiment Metric')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate correlation between pre and post metrics\n",
    "correlation = df['pre_metric'].corr(df['post_metric'])\n",
    "print(f\"Correlation between pre and post metrics: {correlation:.4f}\")\n",
    "```\n",
    "\n",
    "let us also run a traditional t-test on this data:\n",
    "\n",
    "```python\n",
    "def run_ttest(df):\n",
    "    \"\"\"Run a t-test on the post-experiment metric\"\"\"\n",
    "    control = df[df['treatment'] == 0]['post_metric']\n",
    "    treatment = df[df['treatment'] == 1]['post_metric']\n",
    "    \n",
    "    # Calculate means\n",
    "    control_mean = control.mean()\n",
    "    treatment_mean = treatment.mean()\n",
    "    \n",
    "    # Run t-test\n",
    "    t_stat, p_value = stats.ttest_ind(treatment, control, equal_var=False)\n",
    "    \n",
    "    # Calculate standard errors\n",
    "    control_se = control.std() / np.sqrt(len(control))\n",
    "    treatment_se = treatment.std() / np.sqrt(len(treatment))\n",
    "    \n",
    "    # Calculate relative difference\n",
    "    rel_diff = (treatment_mean - control_mean) / control_mean * 100\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Control Mean: {control_mean:.4f} (SE: {control_se:.4f})\")\n",
    "    print(f\"Treatment Mean: {treatment_mean:.4f} (SE: {treatment_se:.4f})\")\n",
    "    print(f\"Absolute Difference: {treatment_mean - control_mean:.4f}\")\n",
    "    print(f\"Relative Difference: {rel_diff:.2f}%\")\n",
    "    print(f\"t-statistic: {t_stat:.4f}\")\n",
    "    print(f\"p-value: {p_value:.4f}\")\n",
    "    print(f\"Statistically Significant (α=0.05): {p_value < 0.05}\")\n",
    "    \n",
    "    return t_stat, p_value\n",
    "\n",
    "print(\"Traditional A/B Test Results:\")\n",
    "t_stat, p_value = run_ttest(df)\n",
    "```\n",
    "\n",
    "## 3. CUPED: The Solution to Variance Reduction\n",
    "\n",
    "CUPED uses pre-experiment data as a control variate to reduce the variance in the post-experiment metric. The key idea is to adjust each user's post-experiment value by subtracting the component that can be predicted from their pre-experiment value.\n",
    "\n",
    "The mathematical formula for CUPED is:\n",
    "\n",
    "Y_i^CUPED = Y_i - θ(X_i - μ_X)\n",
    "\n",
    "Where:\n",
    "- Y_i is the original post-experiment metric for user i\n",
    "- X_i is the pre-experiment metric for user i\n",
    "- μ_X is the mean of the pre-experiment metric\n",
    "- θ is the coefficient that minimizes the variance (typically the ratio of covariance to variance)\n",
    "\n",
    "let us implement CUPED:\n",
    "\n",
    "```python\n",
    "def apply_cuped(df, pre_column='pre_metric', post_column='post_metric'):\n",
    "    \"\"\"\n",
    "    Apply CUPED transformation to the post-experiment metric\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas DataFrame\n",
    "        Data frame containing user data\n",
    "    pre_column : str\n",
    "        Name of the column with pre-experiment data\n",
    "    post_column : str\n",
    "        Name of the column with post-experiment data\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame with added cuped-adjusted column\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate the CUPED coefficient theta\n",
    "    # This is essentially the slope from a linear regression\n",
    "    cov_matrix = np.cov(df[pre_column], df[post_column])\n",
    "    covariance = cov_matrix[0, 1]\n",
    "    variance = cov_matrix[0, 0]\n",
    "    theta = covariance / variance\n",
    "    \n",
    "    # Calculate the mean of pre-experiment metric\n",
    "    pre_mean = df[pre_column].mean()\n",
    "    \n",
    "    # Apply CUPED formula\n",
    "    df[f'{post_column}_cuped'] = df[post_column] - theta * (df[pre_column] - pre_mean)\n",
    "    \n",
    "    print(f\"CUPED coefficient (theta): {theta:.4f}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply CUPED to our data\n",
    "df = apply_cuped(df)\n",
    "\n",
    "# Show first few rows\n",
    "print(\"\\nData after CUPED transformation:\")\n",
    "df.head()\n",
    "```\n",
    "\n",
    "Now let us visualize the effect of CUPED on the data:\n",
    "\n",
    "```python\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot histograms of original vs CUPED-adjusted metrics for control group\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(df[df['treatment'] == 0]['post_metric'], \n",
    "             label='Original', alpha=0.7, kde=True)\n",
    "sns.histplot(df[df['treatment'] == 0]['post_metric_cuped'], \n",
    "             label='CUPED-adjusted', alpha=0.7, kde=True)\n",
    "plt.title('Control Group: Original vs. CUPED-adjusted')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "\n",
    "# Plot histograms of original vs CUPED-adjusted metrics for treatment group\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(df[df['treatment'] == 1]['post_metric'], \n",
    "             label='Original', alpha=0.7, kde=True)\n",
    "sns.histplot(df[df['treatment'] == 1]['post_metric_cuped'], \n",
    "             label='CUPED-adjusted', alpha=0.7, kde=True)\n",
    "plt.title('Treatment Group: Original vs. CUPED-adjusted')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate variance reduction\n",
    "original_variance = df['post_metric'].var()\n",
    "cuped_variance = df['post_metric_cuped'].var()\n",
    "variance_reduction = (1 - cuped_variance / original_variance) * 100\n",
    "\n",
    "print(f\"Original variance: {original_variance:.4f}\")\n",
    "print(f\"CUPED-adjusted variance: {cuped_variance:.4f}\")\n",
    "print(f\"Variance reduction: {variance_reduction:.2f}%\")\n",
    "```\n",
    "\n",
    "Now, let us run a t-test on the CUPED-adjusted data:\n",
    "\n",
    "```python\n",
    "print(\"\\nCUPED-adjusted A/B Test Results:\")\n",
    "df_copy = df.copy()\n",
    "df_copy['post_metric'] = df_copy['post_metric_cuped']  # Using the CUPED-adjusted metric\n",
    "t_stat_cuped, p_value_cuped = run_ttest(df_copy)\n",
    "```\n",
    "\n",
    "## 4. Power Analysis: Quantifying the Benefits of CUPED\n",
    "\n",
    "let us quantify how much CUPED helps in terms of required sample size or experiment duration:\n",
    "\n",
    "```python\n",
    "def calculate_required_sample_size(effect_size, power=0.8, alpha=0.05, variance=None, mean=None, relative_effect=None):\n",
    "    \"\"\"\n",
    "    Calculate required sample size per group for detecting an effect\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    effect_size : float\n",
    "        Cohen's d effect size\n",
    "    power : float\n",
    "        Desired statistical power (default: 0.8)\n",
    "    alpha : float\n",
    "        Significance level (default: 0.05)\n",
    "    variance : float\n",
    "        Variance of the metric (if provided, relative_effect and mean must also be provided)\n",
    "    mean : float\n",
    "        Mean of the metric (if provided, relative_effect and variance must also be provided)\n",
    "    relative_effect : float\n",
    "        Relative effect size as a decimal (if provided, mean and variance must also be provided)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    Required sample size per group\n",
    "    \"\"\"\n",
    "    if variance is not None and mean is not None and relative_effect is not None:\n",
    "        # Convert from relative effect to Cohen's d\n",
    "        absolute_effect = mean * relative_effect\n",
    "        effect_size = absolute_effect / np.sqrt(variance)\n",
    "    \n",
    "    # Calculate required sample size\n",
    "    analysis = TTestIndPower()\n",
    "    sample_size = analysis.solve_power(effect_size=effect_size, \n",
    "                                      power=power, \n",
    "                                      alpha=alpha, \n",
    "                                      ratio=1.0)\n",
    "    \n",
    "    return sample_size\n",
    "\n",
    "def compare_cuped_vs_traditional(df, effect_sizes=[0.01, 0.02, 0.05, 0.1]):\n",
    "    \"\"\"Compare required sample sizes for CUPED vs. traditional approach\"\"\"\n",
    "    # Calculate mean and variances\n",
    "    traditional_mean = df['post_metric'].mean()\n",
    "    traditional_var = df['post_metric'].var()\n",
    "    \n",
    "    cuped_mean = df['post_metric_cuped'].mean()\n",
    "    cuped_var = df['post_metric_cuped'].var()\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for effect in effect_sizes:\n",
    "        # Calculate required sample sizes\n",
    "        trad_size = calculate_required_sample_size(\n",
    "            variance=traditional_var, \n",
    "            mean=traditional_mean,\n",
    "            relative_effect=effect)\n",
    "        \n",
    "        cuped_size = calculate_required_sample_size(\n",
    "            variance=cuped_var, \n",
    "            mean=cuped_mean,\n",
    "            relative_effect=effect)\n",
    "        \n",
    "        # Calculate reduction\n",
    "        reduction = (1 - cuped_size / trad_size) * 100\n",
    "        \n",
    "        results.append({\n",
    "            'Relative Effect Size': f\"{effect * 100}%\",\n",
    "            'Traditional Sample Size': int(trad_size),\n",
    "            'CUPED Sample Size': int(cuped_size),\n",
    "            'Sample Size Reduction': f\"{reduction:.1f}%\"\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Compare sample size requirements\n",
    "comparison_df = compare_cuped_vs_traditional(df)\n",
    "print(\"\\nSample Size Comparison (per group):\")\n",
    "comparison_df\n",
    "```\n",
    "\n",
    "## 5. Simulating Statistical Power with CUPED\n",
    "\n",
    "let us demonstrate how CUPED improves statistical power by simulating multiple experiments:\n",
    "\n",
    "```python\n",
    "def run_simulation(n_simulations=1000, n_users=10000, treatment_effect=2.0, \n",
    "                  pre_post_correlation=0.7):\n",
    "    \"\"\"\n",
    "    Simulate multiple experiments and compare CUPED vs. traditional approach\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    n_simulations : int\n",
    "        Number of simulations to run\n",
    "    n_users : int\n",
    "        Number of users per simulation\n",
    "    treatment_effect : float\n",
    "        True treatment effect to simulate\n",
    "    pre_post_correlation : float\n",
    "        Correlation between pre and post metrics\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame with simulation results\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for i in range(n_simulations):\n",
    "        # Simulate data with treatment effect\n",
    "        df_sim = simulate_user_data(\n",
    "            n_users=n_users, \n",
    "            treatment_effect=treatment_effect,\n",
    "            pre_post_correlation=pre_post_correlation\n",
    "        )\n",
    "        \n",
    "        # Run traditional test\n",
    "        control = df_sim[df_sim['treatment'] == 0]['post_metric']\n",
    "        treatment = df_sim[df_sim['treatment'] == 1]['post_metric']\n",
    "        _, p_value_trad = stats.ttest_ind(treatment, control, equal_var=False)\n",
    "        \n",
    "        # Apply CUPED\n",
    "        df_sim = apply_cuped(df_sim)\n",
    "        \n",
    "        # Run CUPED test\n",
    "        control_cuped = df_sim[df_sim['treatment'] == 0]['post_metric_cuped']\n",
    "        treatment_cuped = df_sim[df_sim['treatment'] == 1]['post_metric_cuped']\n",
    "        _, p_value_cuped = stats.ttest_ind(treatment_cuped, control_cuped, equal_var=False)\n",
    "        \n",
    "        # Store results\n",
    "        results.append({\n",
    "            'simulation': i,\n",
    "            'p_value_trad': p_value_trad,\n",
    "            'p_value_cuped': p_value_cuped,\n",
    "            'significant_trad': p_value_trad < 0.05,\n",
    "            'significant_cuped': p_value_cuped < 0.05\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Run simulation with a smaller effect size that's hard to detect\n",
    "print(\"\\nRunning simulations to compare statistical power...\")\n",
    "sim_results = run_simulation(\n",
    "    n_simulations=100,  # Reduced for notebook performance\n",
    "    n_users=5000,       # Smaller sample size to show the difference\n",
    "    treatment_effect=1.5,  # Small effect that's hard to detect\n",
    "    pre_post_correlation=0.7\n",
    ")\n",
    "\n",
    "# Calculate power (percentage of significant results)\n",
    "trad_power = sim_results['significant_trad'].mean() * 100\n",
    "cuped_power = sim_results['significant_cuped'].mean() * 100\n",
    "\n",
    "print(f\"\\nStatistical Power Comparison:\")\n",
    "print(f\"Traditional A/B Test Power: {trad_power:.1f}%\")\n",
    "print(f\"CUPED A/B Test Power: {cuped_power:.1f}%\")\n",
    "print(f\"Power Improvement: {cuped_power - trad_power:.1f} percentage points\")\n",
    "\n",
    "# Visualize p-value distributions\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(sim_results['p_value_trad'], bins=20, alpha=0.5, label='Traditional')\n",
    "plt.hist(sim_results['p_value_cuped'], bins=20, alpha=0.5, label='CUPED')\n",
    "plt.axvline(0.05, color='red', linestyle='--', label='α = 0.05')\n",
    "plt.xlabel('p-value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of p-values: Traditional vs. CUPED')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "## 6. Best Practices for Implementing CUPED\n",
    "\n",
    "Here are some best practices when implementing CUPED in real-world A/B testing:\n",
    "\n",
    "### 6.1 Selecting the Right Control Covariates\n",
    "\n",
    "The pre-experiment data used for CUPED should be:\n",
    "\n",
    "```python\n",
    "def demo_covariate_selection():\n",
    "    \"\"\"Demonstrate covariate selection for CUPED\"\"\"\n",
    "                             \n",
    "    # let us simulate additional pre-experiment metrics with different correlations\n",
    "    n_users = 10000\n",
    "    df_covariates = simulate_user_data(n_users=n_users, treatment_effect=2)\n",
    "    \n",
    "    # Add more potential covariates\n",
    "    # High correlation covariate\n",
    "    df_covariates['pre_metric_high_corr'] = (\n",
    "        df_covariates['post_metric'] * 0.8 + \n",
    "        np.random.normal(0, 5, n_users)\n",
    "    )\n",
    "    \n",
    "    # Medium correlation covariate\n",
    "    df_covariates['pre_metric_med_corr'] = (\n",
    "        df_covariates['post_metric'] * 0.5 + \n",
    "        np.random.normal(0, 10, n_users)\n",
    "    )\n",
    "    \n",
    "    # Low correlation covariate\n",
    "    df_covariates['pre_metric_low_corr'] = (\n",
    "        df_covariates['post_metric'] * 0.2 + \n",
    "        np.random.normal(0, 15, n_users)\n",
    "    )\n",
    "    \n",
    "    # Zero correlation covariate\n",
    "    df_covariates['pre_metric_no_corr'] = np.random.normal(20, 10, n_users)\n",
    "    \n",
    "    # Calculate correlations\n",
    "    covariates = ['pre_metric', 'pre_metric_high_corr', 'pre_metric_med_corr', \n",
    "                 'pre_metric_low_corr', 'pre_metric_no_corr']\n",
    "    \n",
    "    correlations = []\n",
    "    variances = []\n",
    "    cuped_variances = []\n",
    "    \n",
    "    for covariate in covariates:\n",
    "        # Calculate correlation\n",
    "        corr = df_covariates[covariate].corr(df_covariates['post_metric'])\n",
    "        correlations.append(corr)\n",
    "        \n",
    "        # Apply CUPED with this covariate\n",
    "        df_temp = apply_cuped(df_covariates.copy(), pre_column=covariate)\n",
    "        \n",
    "        # Calculate variances\n",
    "        orig_var = df_temp['post_metric'].var()\n",
    "        cuped_var = df_temp['post_metric_cuped'].var()\n",
    "        \n",
    "        variances.append(orig_var)\n",
    "        cuped_variances.append(cuped_var)\n",
    "    \n",
    "    # Create results table\n",
    "    results = pd.DataFrame({\n",
    "        'Covariate': covariates,\n",
    "        'Correlation with Post-Metric': correlations,\n",
    "        'Original Variance': variances,\n",
    "        'CUPED Variance': cuped_variances,\n",
    "        'Variance Reduction': [(1 - cv/ov)*100 for cv, ov in zip(cuped_variances, variances)]\n",
    "    })\n",
    "    \n",
    "    return results\n",
    "\n",
    "covariate_results = demo_covariate_selection()\n",
    "print(\"\\nCovariate Selection Analysis:\")\n",
    "covariate_results\n",
    "```\n",
    "\n",
    "### 6.2. Multiple Covariates with CUPED\n",
    "\n",
    "In practice, we often have multiple pre-experiment metrics. CUPED can be extended to use multiple covariates:\n",
    "\n",
    "```python\n",
    "def apply_multi_cuped(df, pre_columns, post_column='post_metric'):\n",
    "    \"\"\"\n",
    "    Apply CUPED with multiple covariates\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas DataFrame\n",
    "        Data frame containing user data\n",
    "    pre_columns : list of str\n",
    "        Names of columns with pre-experiment data\n",
    "    post_column : str\n",
    "        Name of the column with post-experiment data\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame with added cuped-adjusted column\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a copy to avoid modifying the original\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Extract pre-experiment features and post-experiment metric\n",
    "    X = df_copy[pre_columns].values\n",
    "    y = df_copy[post_column].values\n",
    "    \n",
    "    # Add a constant for the intercept\n",
    "    X = sm.add_constant(X)\n",
    "    \n",
    "    # Fit linear regression model\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    \n",
    "    # Get the coefficient for each feature\n",
    "    coefficients = model.params[1:]  # Skip the intercept\n",
    "    \n",
    "    # Calculate the mean of each pre-experiment metric\n",
    "    pre_means = df_copy[pre_columns].mean()\n",
    "    \n",
    "    # Apply CUPED formula with multiple covariates\n",
    "    df_copy[f'{post_column}_multi_cuped'] = df_copy[post_column].copy()\n",
    "    \n",
    "    for i, col in enumerate(pre_columns):\n",
    "        df_copy[f'{post_column}_multi_cuped'] -= (\n",
    "            coefficients[i] * (df_copy[col] - pre_means[col])\n",
    "        )\n",
    "    \n",
    "    print(f\"CUPED coefficients: {coefficients}\")\n",
    "    \n",
    "    return df_copy\n",
    "\n",
    "# let us use the dataset with multiple covariates\n",
    "multi_cuped_df = df.copy()\n",
    "\n",
    "# Add some additional pre-experiment metrics\n",
    "n_users = len(multi_cuped_df)\n",
    "multi_cuped_df['pre_metric_2'] = (\n",
    "    multi_cuped_df['pre_metric'] * 0.6 + \n",
    "    np.random.normal(0, 5, n_users)\n",
    ")\n",
    "multi_cuped_df['pre_metric_3'] = (\n",
    "    multi_cuped_df['post_metric'] * 0.3 + \n",
    "    np.random.normal(0, 8, n_users)\n",
    ")\n",
    "\n",
    "# Apply multiple covariate CUPED\n",
    "multi_cuped_result = apply_multi_cuped(\n",
    "    multi_cuped_df, \n",
    "    pre_columns=['pre_metric', 'pre_metric_2', 'pre_metric_3']\n",
    ")\n",
    "\n",
    "# Compare variances\n",
    "original_var = multi_cuped_result['post_metric'].var()\n",
    "single_cuped_var = multi_cuped_result['post_metric_cuped'].var()\n",
    "multi_cuped_var = multi_cuped_result['post_metric_multi_cuped'].var()\n",
    "\n",
    "print(\"\\nMultiple Covariate CUPED Results:\")\n",
    "print(f\"Original variance: {original_var:.4f}\")\n",
    "print(f\"Single covariate CUPED variance: {single_cuped_var:.4f}\")\n",
    "print(f\"Multiple covariate CUPED variance: {multi_cuped_var:.4f}\")\n",
    "print(f\"Single CUPED variance reduction: {(1 - single_cuped_var/original_var)*100:.2f}%\")\n",
    "print(f\"Multiple CUPED variance reduction: {(1 - multi_cuped_var/original_var)*100:.2f}%\")\n",
    "```\n",
    "\n",
    "### 6.3. Stratified Analysis with CUPED\n",
    "\n",
    "CUPED can be combined with stratification for even better results:\n",
    "\n",
    "```python\n",
    "def apply_stratified_cuped(df, strata_column, pre_column='pre_metric', post_column='post_metric'):\n",
    "    \"\"\"\n",
    "    Apply CUPED separately for each stratum\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas DataFrame\n",
    "        Data frame containing user data\n",
    "    strata_column : str\n",
    "        Name of the column used for stratification\n",
    "    pre_column : str\n",
    "        Name of the column with pre-experiment data\n",
    "    post_column : str\n",
    "        Name of the column with post-experiment data\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame with added cuped-adjusted column\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying the original\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Initialize the CUPED-adjusted column\n",
    "    df_copy[f'{post_column}_stratified_cuped'] = np.nan\n",
    "    \n",
    "    # Apply CUPED separately for each stratum\n",
    "    strata = df_copy[strata_column].unique()\n",
    "    \n",
    "    print(f\"Applying stratified CUPED for {len(strata)} strata:\")\n",
    "    \n",
    "    for stratum in strata:\n",
    "        # Filter for this stratum\n",
    "        mask = df_copy[strata_column] == stratum\n",
    "        stratum_df = df_copy[mask].copy()\n",
    "        \n",
    "        # Calculate the CUPED coefficient theta for this stratum\n",
    "        cov_matrix = np.cov(stratum_df[pre_column], stratum_df[post_column])\n",
    "        covariance = cov_matrix[0, 1]\n",
    "        variance = cov_matrix[0, 0]\n",
    "        theta = covariance / variance if variance > 0 else 0\n",
    "        \n",
    "        # Calculate the mean of pre-experiment metric for this stratum\n",
    "        pre_mean = stratum_df[pre_column].mean()\n",
    "        \n",
    "        # Apply CUPED formula\n",
    "        df_copy.loc[mask, f'{post_column}_stratified_cuped'] = (\n",
    "            df_copy.loc[mask, post_column] - \n",
    "            theta * (df_copy.loc[mask, pre_column] - pre_mean)\n",
    "        )\n",
    "        \n",
    "        print(f\"  - {stratum}: CUPED coefficient = {theta:.4f}\")\n",
    "    \n",
    "    return df_copy\n",
    "\n",
    "# Apply stratified CUPED by cohort\n",
    "strat_cuped_df = apply_stratified_cuped(df, strata_column='cohort')\n",
    "\n",
    "# Compare variances\n",
    "original_var = strat_cuped_df['post_metric'].var()\n",
    "cuped_var = strat_cuped_df['post_metric_cuped'].var()\n",
    "strat_cuped_var = strat_cuped_df['post_metric_stratified_cuped'].var()\n",
    "\n",
    "print(\"\\nStratified CUPED Results:\")\n",
    "print(f\"Original variance: {original_var:.4f}\")\n",
    "print(f\"Standard CUPED variance: {cuped_var:.4f}\")\n",
    "print(f\"Stratified CUPED variance: {strat_cuped_var:.4f}\")\n",
    "print(f\"Standard CUPED variance reduction: {(1 - cuped_var/original_var)*100:.2f}%\")\n",
    "print(f\"Stratified CUPED variance reduction: {(1 - strat_cuped_var/original_var)*100:.2f}%\")\n",
    "```\n",
    "\n",
    "## 7. Real-world Example: E-commerce Revenue Analysis\n",
    "\n",
    "let us look at a more realistic e-commerce example:\n",
    "\n",
    "```python\n",
    "def simulate_ecommerce_data(n_users=10000, treatment_effect=0):\n",
    "    \"\"\"Simulate e-commerce user data\"\"\"\n",
    "    user_ids = np.arange(n_users)\n",
    "    treatment = np.random.binomial(1, 0.5, n_users)\n",
    "    \n",
    "    # User segments\n",
    "    segments = np.random.choice(['New', 'Returning', 'VIP'], n_users, p=[0.6, 0.3, 0.1])\n",
    "    \n",
    "    # Segment-specific base spending\n",
    "    base_spending = np.zeros(n_users)\n",
    "    base_spending[segments == 'New'] = np.random.exponential(20, np.sum(segments == 'New'))\n",
    "    base_spending[segments == 'Returning'] = np.random.exponential(50, np.sum(segments == 'Returning'))\n",
    "    base_spending[segments == 'VIP'] = np.random.exponential(200, np.sum(segments == 'VIP'))\n",
    "    \n",
    "    # Add user-specific noise that's consistent over time\n",
    "    user_noise = np.random.exponential(base_spending * 0.5)\n",
    "    \n",
    "    # Pre-experiment spending (last month)\n",
    "    pre_spending = base_spending + user_noise\n",
    "    \n",
    "    # Simulate a natural purchase pattern where ~70% of users don't purchase in a given month\n",
    "    purchase_mask = np.random.binomial(1, 0.3, n_users).astype(bool)\n",
    "    pre_spending = pre_spending * purchase_mask\n",
    "    \n",
    "    # Post-experiment spending\n",
    "    purchase_mask_post = np.random.binomial(1, 0.3 + 0.02 * treatment, n_users).astype(bool)\n",
    "    post_spending = (\n",
    "        base_spending * (1 + 0.05 * np.random.rand(n_users)) +  # Some natural growth\n",
    "        user_noise +  # Consistent user noise\n",
    "        treatment_effect * treatment * base_spending * 0.01 +  # Treatment effect\n",
    "        np.random.exponential(5, n_users)  # Random noise specific to this period\n",
    "    ) * purchase_mask_post\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'user_id': user_ids,\n",
    "        'treatment': treatment,\n",
    "        'segment': segments,\n",
    "        'pre_spending': pre_spending,\n",
    "        'post_spending': post_spending\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Simulate e-commerce data with a small treatment effect\n",
    "ecom_df = simulate_ecommerce_data(n_users=20000, treatment_effect=2)\n",
    "\n",
    "print(\"\\nE-commerce data summary:\")\n",
    "print(ecom_df.describe())\n",
    "\n",
    "# Show distribution of spending\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(ecom_df['post_spending'], bins=50, log_scale=True)\n",
    "plt.title('Distribution of Post-Experiment Spending')\n",
    "plt.xlabel('Spending')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(data=ecom_df, x='segment', y='post_spending', showfliers=False)\n",
    "plt.title('Post-Experiment Spending by Segment')\n",
    "plt.xlabel('User Segment')\n",
    "plt.ylabel('Spending')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Run traditional t-test\n",
    "print(\"\\nTraditional A/B Test Results (E-commerce):\")\n",
    "trad_ttest = run_ttest(ecom_df.rename(columns={'post_spending': 'post_metric'}))\n",
    "\n",
    "# Apply CUPED\n",
    "ecom_cuped_df = apply_cuped(\n",
    "    ecom_df.rename(columns={'pre_spending': 'pre_metric', 'post_spending': 'post_metric'})\n",
    ")\n",
    "\n",
    "# Run CUPED t-test\n",
    "print(\"\\nCUPED-adjusted A/B Test Results (E-commerce):\")\n",
    "ecom_df_copy = ecom_cuped_df.copy()\n",
    "ecom_df_copy['post_metric'] = ecom_df_copy['post_metric_cuped']\n",
    "cuped_ttest = run_ttest(ecom_df_copy)\n",
    "\n",
    "# Apply stratified CUPED\n",
    "print(\"\\nApplying stratified CUPED by user segment:\")\n",
    "ecom_strat_df = apply_stratified_cuped(\n",
    "    ecom_df.rename(columns={'pre_spending': 'pre_metric', 'post_spending': 'post_metric'}),\n",
    "    strata_column='segment'\n",
    ")\n",
    "\n",
    "# Run stratified CUPED t-test\n",
    "print(\"\\nStratified CUPED-adjusted A/B Test Results (E-commerce):\")\n",
    "ecom_strat_copy = ecom_strat_df.copy()\n",
    "ecom_strat_copy['post_metric'] = ecom_strat_copy['post_metric_stratified_cuped']\n",
    "strat_cuped_ttest = run_ttest(ecom_strat_copy)\n",
    "\n",
    "## 8. Common Pitfalls and Solutions\n",
    "\n",
    "While CUPED is powerful, there are some common pitfalls to be aware of:\n",
    "\n",
    "### 8.1 Checking Assumptions\n",
    "\n",
    "```python\n",
    "def check_cuped_assumptions(df, pre_column='pre_metric', post_column='post_metric'):\n",
    "    \n",
    "    \"\"\"Check assumptions for CUPED application\"\"\"\n",
    "\n",
    "    # 1. Check for correlation between pre and post metrics\n",
    "    correlation = df[pre_column].corr(df[post_column])\n",
    "    \n",
    "    # 2. Check for balance in pre-experiment metric between treatment and control\n",
    "    control_pre = df[df['treatment'] == 0][pre_column]\n",
    "    treatment_pre = df[df['treatment'] == 1][pre_column]\n",
    "    \n",
    "    t_stat, p_value = stats.ttest_ind(treatment_pre, control_pre, equal_var=False)\n",
    "    \n",
    "    # 3. Verify that pre-experiment data is not affected by the treatment\n",
    "    # (This is logical rather than statistical check in most cases)\n",
    "    \n",
    "    # 4. Check linear relationship assumption\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(data=df, x=pre_column, y=post_column, alpha=0.3)\n",
    "    \n",
    "    # Add a regression line\n",
    "    x = df[pre_column].values.reshape(-1, 1)\n",
    "    y = df[post_column].values\n",
    "    reg = LinearRegression().fit(x, y)\n",
    "    plt.plot(sorted(df[pre_column]), reg.predict(sorted(df[pre_column]).reshape(-1, 1)), 'r')\n",
    "    \n",
    "    plt.title('Checking Linear Relationship Between Pre and Post Metrics')\n",
    "    plt.xlabel('Pre-Experiment Metric')\n",
    "    plt.ylabel('Post-Experiment Metric')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print results\n",
    "    print(\"CUPED Assumptions Check:\")\n",
    "    print(f\"1. Correlation between pre and post metrics: {correlation:.4f}\")\n",
    "    print(f\"   (Higher correlation means more effective variance reduction)\")\n",
    "    \n",
    "    print(f\"\\n2. Balance in pre-experiment metric:\")\n",
    "    print(f\"   Control mean: {control_pre.mean():.4f}\")\n",
    "    print(f\"   Treatment mean: {treatment_pre.mean():.4f}\")\n",
    "    print(f\"   p-value: {p_value:.4f}\")\n",
    "    \n",
    "    if p_value < 0.05:\n",
    "        print(\"   WARNING: Pre-experiment metrics are not balanced between groups!\")\n",
    "        print(\"   This could indicate randomization issues or selection bias.\")\n",
    "    else:\n",
    "        print(\"   Pre-experiment metrics are balanced between groups.\")\n",
    "    \n",
    "    print(\"\\n3. Ensure pre-experiment data was not affected by the treatment:\")\n",
    "    print(\"   This is a logical check - the pre-experiment data should be collected\")\n",
    "    print(\"   before the treatment was applied and cannot be influenced by it.\")\n",
    "    \n",
    "    print(\"\\n4. Linear relationship: Check the scatter plot above.\")\n",
    "    print(\"   The relationship should be approximately linear for optimal CUPED performance.\")\n",
    "\n",
    "# Check assumptions for our e-commerce dataset\n",
    "check_cuped_assumptions(\n",
    "    ecom_df.rename(columns={'pre_spending': 'pre_metric', 'post_spending': 'post_metric'})\n",
    ")\n",
    "```\n",
    "\n",
    "### 8.2 Data Leakage\n",
    "\n",
    "A common issue with CUPED is data leakage - when pre-experiment data is affected by the treatment or affected by the same factors that will affect the treatment:\n",
    "\n",
    "```python\n",
    "def demonstrate_data_leakage():\n",
    "    \"\"\"Demonstrate the problem of data leakage in CUPED\"\"\"\n",
    "\n",
    "    # Simulate a scenario where the pre-experiment data is affected by \n",
    "    # the same factor that will affect the treatment\n",
    "    n_users = 10000\n",
    "    \n",
    "    # User treatment assignment\n",
    "    treatment = np.random.binomial(1, 0.5, n_users)\n",
    "    \n",
    "    # Underlying user characteristic that affects both pre and post metrics\n",
    "    # AND is correlated with treatment assignment (data leakage)\n",
    "    user_type = np.random.normal(0.5 * treatment, 1, n_users)\n",
    "    \n",
    "    # Pre-experiment metric (affected by user type)\n",
    "    pre_metric = 10 + 5 * user_type + np.random.normal(0, 5, n_users)\n",
    "    \n",
    "    # Post-experiment metric (affected by user type and treatment)\n",
    "    treatment_effect = 2  # True treatment effect\n",
    "    post_metric = (\n",
    "        20 + \n",
    "        8 * user_type +  # User type effect\n",
    "        treatment_effect * treatment +  # Treatment effect\n",
    "        np.random.normal(0, 5, n_users)  # Random noise\n",
    "    )\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df_leakage = pd.DataFrame({\n",
    "        'user_id': np.arange(n_users),\n",
    "        'treatment': treatment,\n",
    "        'user_type': user_type,\n",
    "        'pre_metric': pre_metric,\n",
    "        'post_metric': post_metric\n",
    "    })\n",
    "    \n",
    "    # Check balance in pre-experiment metric\n",
    "    control_pre = df_leakage[df_leakage['treatment'] == 0]['pre_metric']\n",
    "    treatment_pre = df_leakage[df_leakage['treatment'] == 1]['pre_metric']\n",
    "    \n",
    "    t_stat, p_value = stats.ttest_ind(treatment_pre, control_pre, equal_var=False)\n",
    "    \n",
    "    # Run traditional A/B test\n",
    "    print(\"Traditional A/B Test Results (Data Leakage Scenario):\")\n",
    "    trad_ttest = run_ttest(df_leakage)\n",
    "    \n",
    "    # Apply CUPED\n",
    "    leakage_cuped_df = apply_cuped(df_leakage)\n",
    "    \n",
    "    # Run CUPED t-test\n",
    "    print(\"\\nCUPED-adjusted A/B Test Results (Data Leakage Scenario):\")\n",
    "    leakage_df_copy = leakage_cuped_df.copy()\n",
    "    leakage_df_copy['post_metric'] = leakage_df_copy['post_metric_cuped']\n",
    "    cuped_ttest = run_ttest(leakage_df_copy)\n",
    "    \n",
    "    # Print warning\n",
    "    print(\"\\nData Leakage Check:\")\n",
    "    print(f\"Balance in pre-experiment metric (p-value): {p_value:.4f}\")\n",
    "    \n",
    "    if p_value < 0.05:\n",
    "        print(\"WARNING: Pre-experiment metrics are not balanced between groups!\")\n",
    "        print(\"This suggests potential data leakage or randomization issues.\")\n",
    "        print(\"In this case, CUPED may not provide reliable results.\")\n",
    "    \n",
    "    return df_leakage\n",
    "\n",
    "# Demonstrate data leakage\n",
    "leakage_df = demonstrate_data_leakage()\n",
    "```\n",
    "\n",
    "### 8.3 Solutions to Common Problems\n",
    "\n",
    "```python\n",
    "def demonstrate_solutions():\n",
    "    \"\"\"Demonstrate solutions to common CUPED problems\"\"\"\n",
    "    # Create a copy of the leakage dataset\n",
    "    df = leakage_df.copy()\n",
    "    \n",
    "    print(\"\\nSolutions to Common CUPED Problems:\")\n",
    "    \n",
    "    # 1. Handling data leakage with matched pre-experiment periods\n",
    "    print(\"\\n1. Using matched pre-experiment periods:\")\n",
    "    print(\"   Instead of using the most recent pre-experiment data, use data from\")\n",
    "    print(\"   the same time period in the previous year/quarter/month to avoid seasonal effects.\")\n",
    "    \n",
    "    # 2. Using a regression model instead of simple CUPED\n",
    "    print(\"\\n2. Using a regression model approach:\")\n",
    "    \n",
    "    # Fit a regression model\n",
    "    X = df[['pre_metric', 'treatment']]\n",
    "    X = sm.add_constant(X)\n",
    "    y = df['post_metric']\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    \n",
    "    print(model.summary().tables[1])\n",
    "    \n",
    "    print(\"\\n   This approach allows us to estimate the treatment effect while\")\n",
    "    print(\"   controlling for pre-experiment differences.\")\n",
    "    \n",
    "    # 3. Using propensity score matching\n",
    "    print(\"\\n3. Using propensity score matching:\")\n",
    "    print(\"   If randomization is compromised, propensity score matching can help\")\n",
    "    print(\"   create balanced treatment and control groups based on covariates.\")\n",
    "    \n",
    "    # Simulate propensity score matching results\n",
    "    matched_control_mean = df[df['treatment'] == 1]['pre_metric'].mean() * 0.98\n",
    "    matched_treatment_mean = df[df['treatment'] == 1]['pre_metric'].mean()\n",
    "    \n",
    "    print(f\"   Before matching: Control mean = {df[df['treatment'] == 0]['pre_metric'].mean():.4f}, \"\n",
    "          f\"Treatment mean = {df[df['treatment'] == 1]['pre_metric'].mean():.4f}\")\n",
    "    print(f\"   After matching:  Control mean = {matched_control_mean:.4f}, \"\n",
    "          f\"Treatment mean = {matched_treatment_mean:.4f}\")\n",
    "\n",
    "# Demonstrate solutions\n",
    "demonstrate_solutions()\n",
    "```\n",
    "\n",
    "## 9. Advanced CUPED Applications\n",
    "\n",
    "### 9.1 CUPED for Non-Normal Metrics\n",
    "\n",
    "For metrics like conversion rates or counts that follow non-normal distributions, we can adapt CUPED:\n",
    "\n",
    "```python\n",
    "def apply_cuped_for_binary_metric(df, pre_column='pre_conversion', post_column='post_conversion'):\n",
    "    \"\"\"Apply CUPED for binary metrics like conversion rate\"\"\"\n",
    "    # For binary metrics, we can use a similar approach as standard CUPED\n",
    "    # but we need to be careful about interpretation\n",
    "    \n",
    "    # Calculate the CUPED coefficient theta\n",
    "    cov_matrix = np.cov(df[pre_column], df[post_column])\n",
    "    covariance = cov_matrix[0, 1]\n",
    "    variance = cov_matrix[0, 0]\n",
    "    theta = covariance / variance if variance > 0 else 0\n",
    "    \n",
    "    # Calculate the mean of pre-experiment metric\n",
    "    pre_mean = df[pre_column].mean()\n",
    "    \n",
    "    # Apply CUPED formula\n",
    "    df[f'{post_column}_cuped'] = df[post_column] - theta * (df[pre_column] - pre_mean)\n",
    "    \n",
    "    print(f\"CUPED coefficient (theta) for binary metric: {theta:.4f}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Simulate conversion rate data\n",
    "def simulate_conversion_data(n_users=20000, treatment_effect=0.02):\n",
    "    \"\"\"Simulate conversion rate data\"\"\"\n",
    "    user_ids = np.arange(n_users)\n",
    "    treatment = np.random.binomial(1, 0.5, n_users)\n",
    "    \n",
    "    # User-level propensity to convert (latent variable)\n",
    "    convert_propensity = np.random.beta(1, 9, n_users)  # Most users have low conversion probability\n",
    "    \n",
    "    # Pre-experiment conversion (binary)\n",
    "    pre_conversion = np.random.binomial(1, convert_propensity, n_users)\n",
    "    \n",
    "    # Post-experiment conversion with treatment effect\n",
    "    post_conversion_prob = np.clip(\n",
    "        convert_propensity + treatment_effect * treatment,\n",
    "        0, 1\n",
    "    )\n",
    "    post_conversion = np.random.binomial(1, post_conversion_prob, n_users)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'user_id': user_ids,\n",
    "        'treatment': treatment,\n",
    "        'pre_conversion': pre_conversion,\n",
    "        'post_conversion': post_conversion\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Simulate conversion data\n",
    "conv_df = simulate_conversion_data(n_users=20000, treatment_effect=0.02)\n",
    "\n",
    "# Analyze original data\n",
    "control_conv = conv_df[conv_df['treatment'] == 0]['post_conversion'].mean()\n",
    "treatment_conv = conv_df[conv_df['treatment'] == 1]['post_conversion'].mean()\n",
    "\n",
    "print(\"\\nConversion Rate Analysis:\")\n",
    "print(f\"Control conversion rate: {control_conv:.4f}\")\n",
    "print(f\"Treatment conversion rate: {treatment_conv:.4f}\")\n",
    "print(f\"Absolute lift: {treatment_conv - control_conv:.4f}\")\n",
    "print(f\"Relative lift: {(treatment_conv - control_conv) / control_conv * 100:.2f}%\")\n",
    "\n",
    "# Run traditional conversion rate test\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "\n",
    "count_treatment = conv_df[conv_df['treatment'] == 1]['post_conversion'].sum()\n",
    "count_control = conv_df[conv_df['treatment'] == 0]['post_conversion'].sum()\n",
    "nobs_treatment = len(conv_df[conv_df['treatment'] == 1])\n",
    "nobs_control = len(conv_df[conv_df['treatment'] == 0])\n",
    "\n",
    "z_stat, p_value = proportions_ztest(\n",
    "    [count_treatment, count_control],\n",
    "    [nobs_treatment, nobs_control]\n",
    ")\n",
    "\n",
    "print(\"\\nTraditional Conversion Rate Test:\")\n",
    "print(f\"z-statistic: {z_stat:.4f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "\n",
    "# Apply CUPED for binary metric\n",
    "conv_cuped_df = apply_cuped_for_binary_metric(conv_df)\n",
    "\n",
    "# Run t-test on CUPED-adjusted values\n",
    "control_cuped = conv_cuped_df[conv_cuped_df['treatment'] == 0]['post_conversion_cuped']\n",
    "treatment_cuped = conv_cuped_df[conv_cuped_df['treatment'] == 1]['post_conversion_cuped']\n",
    "\n",
    "t_stat, p_value = stats.ttest_ind(treatment_cuped, control_cuped, equal_var=False)\n",
    "\n",
    "print(\"\\nCUPED-adjusted Conversion Rate Test:\")\n",
    "print(f\"t-statistic: {t_stat:.4f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "```\n",
    "\n",
    "### 9.2 CUPED for Mobile App Experiments\n",
    "\n",
    "In mobile app experiments, we often have sparse data due to low engagement. CUPED can help:\n",
    "\n",
    "```python\n",
    "def simulate_mobile_app_data(n_users=10000, treatment_effect=0.1):\n",
    "    \"\"\"Simulate mobile app engagement data\"\"\"\n",
    "\n",
    "    user_ids = np.arange(n_users)\n",
    "    treatment = np.random.binomial(1, 0.5, n_users)\n",
    "    \n",
    "    # User engagement level (highly skewed)\n",
    "    engagement_level = np.random.exponential(1, n_users)\n",
    "    \n",
    "    # Days of usage in pre-experiment period (30 days)\n",
    "    pre_days_used = np.random.binomial(30, 0.1 + 0.2 * engagement_level / np.max(engagement_level))\n",
    "    \n",
    "    # Session count in pre-experiment period\n",
    "    pre_sessions = np.round(pre_days_used * (1 + engagement_level))\n",
    "    \n",
    "    # Time spent in pre-experiment period (minutes)\n",
    "    pre_time_spent = pre_sessions * (2 + 8 * engagement_level / np.max(engagement_level))\n",
    "    \n",
    "    # Treatment effect on engagement\n",
    "    effect_multiplier = 1 + treatment_effect * treatment\n",
    "    \n",
    "    # Post-experiment metrics\n",
    "    post_days_used = np.random.binomial(\n",
    "        30, \n",
    "        (0.1 + 0.2 * engagement_level / np.max(engagement_level)) * effect_multiplier\n",
    "    )\n",
    "    post_sessions = np.round(post_days_used * (1 + engagement_level) * effect_multiplier)\n",
    "    post_time_spent = post_sessions * (2 + 8 * engagement_level / np.max(engagement_level))\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'user_id': user_ids,\n",
    "        'treatment': treatment,\n",
    "        'pre_days_used': pre_days_used,\n",
    "        'pre_sessions': pre_sessions,\n",
    "        'pre_time_spent': pre_time_spent,\n",
    "        'post_days_used': post_days_used,\n",
    "        'post_sessions': post_sessions,\n",
    "        'post_time_spent': post_time_spent\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Simulate mobile app data\n",
    "mobile_df = simulate_mobile_app_data(n_users=10000, treatment_effect=0.1)\n",
    "\n",
    "print(\"\\nMobile App Experiment Data:\")\n",
    "print(mobile_df[['pre_days_used', 'pre_sessions', 'pre_time_spent',\n",
    "                'post_days_used', 'post_sessions', 'post_time_spent']].describe())\n",
    "\n",
    "# Visualize the typical long-tail distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(mobile_df['post_sessions'], bins=50, log_y=True)\n",
    "plt.title('Distribution of Sessions (Post-Experiment)')\n",
    "plt.xlabel('Number of Sessions')\n",
    "plt.ylabel('Log Frequency')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(mobile_df['post_time_spent'], bins=50, log_y=True)\n",
    "plt.title('Distribution of Time Spent (Post-Experiment)')\n",
    "plt.xlabel('Minutes')\n",
    "plt.ylabel('Log Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Apply CUPED to each metric\n",
    "metrics = ['days_used', 'sessions', 'time_spent']\n",
    "\n",
    "for metric in metrics:\n",
    "    # Traditional test\n",
    "    print(f\"\\nTraditional A/B Test for {metric}:\")\n",
    "    temp_df = mobile_df.rename(columns={\n",
    "        f'pre_{metric}': 'pre_metric',\n",
    "        f'post_{metric}': 'post_metric'\n",
    "    })\n",
    "    run_ttest(temp_df)\n",
    "    \n",
    "    # Apply CUPED\n",
    "    print(f\"\\nCUPED-adjusted A/B Test for {metric}:\")\n",
    "    cuped_df = apply_cuped(temp_df)\n",
    "    cuped_df['post_metric'] = cuped_df['post_metric_cuped']\n",
    "    run_ttest(cuped_df)\n",
    "```\n",
    "\n",
    "## 10. Conclusion and CUPED Best Practices\n",
    "\n",
    "CUPED is a powerful technique for improving the sensitivity of A/B tests by reducing metric variance. Here's a summary of when and how to use it effectively:\n",
    "\n",
    "```python\n",
    "def summarize_cuped_benefits(df):\n",
    "    \"\"\"Summarize the benefits of CUPED across different metrics\"\"\"\n",
    "    # Define metrics with different variance profiles\n",
    "    n_users = len(df)\n",
    "    \n",
    "    # High-variance metric (similar to revenue)\n",
    "    df['high_var_pre'] = np.random.exponential(100, n_users)\n",
    "    df['high_var_post'] = df['high_var_pre'] * 1.1 + df['treatment'] * 10 + np.random.exponential(80, n_users)\n",
    "    \n",
    "    # Medium-variance metric (similar to engagement)\n",
    "    df['med_var_pre'] = np.random.gamma(5, 5, n_users)\n",
    "    df['med_var_post'] = df['med_var_pre'] * 1.05 + df['treatment'] * 2 + np.random.gamma(3, 5, n_users)\n",
    "    \n",
    "    # Low-variance metric (similar to conversion)\n",
    "    conversion_propensity = np.random.beta(2, 18, n_users)\n",
    "    df['low_var_pre'] = np.random.binomial(1, conversion_propensity, n_users)\n",
    "    df['low_var_post'] = np.random.binomial(1, conversion_propensity + 0.01 * df['treatment'], n_users)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Test each metric with and without CUPED\n",
    "    for var_level, prefix in [('High', 'high_var'), ('Medium', 'med_var'), ('Low', 'low_var')]:\n",
    "        # Traditional test\n",
    "        temp_df = df.rename(columns={\n",
    "            f'{prefix}_pre': 'pre_metric',\n",
    "            f'{prefix}_post': 'post_metric'\n",
    "        })\n",
    "        \n",
    "        # Calculate original variance\n",
    "        orig_var = temp_df['post_metric'].var()\n",
    "        \n",
    "        # Run traditional test\n",
    "        _, p_value_trad = stats.ttest_ind(\n",
    "            temp_df[temp_df['treatment'] == 1]['post_metric'],\n",
    "            temp_df[temp_df['treatment'] == 0]['post_metric'],\n",
    "            equal_var=False\n",
    "        )\n",
    "        \n",
    "        # Apply CUPED\n",
    "        cuped_df = apply_cuped(temp_df)\n",
    "        \n",
    "        # Calculate CUPED variance\n",
    "        cuped_var = cuped_df['post_metric_cuped'].var()\n",
    "        \n",
    "        # Run CUPED test\n",
    "        _, p_value_cuped = stats.ttest_ind(\n",
    "            cuped_df[cuped_df['treatment'] == 1]['post_metric_cuped'],\n",
    "            cuped_df[cuped_df['treatment'] == 0]['post_metric_cuped'],\n",
    "            equal_var=False\n",
    "        )\n",
    "        \n",
    "        # Calculate improvement\n",
    "        var_reduction = (1 - cuped_var / orig_var) * 100\n",
    "        \n",
    "        # Calculate sample size reduction\n",
    "        sample_reduction = (1 - np.sqrt(cuped_var) / np.sqrt(orig_var)) * 100\n",
    "        \n",
    "        results.append({\n",
    "            'Variance Level': var_level,\n",
    "            'Original p-value': p_value_trad,\n",
    "            'CUPED p-value': p_value_cuped,\n",
    "            'Variance Reduction': f\"{var_reduction:.1f}%\",\n",
    "            'Sample Size Reduction': f\"{sample_reduction:.1f}%\"\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Show benefits summary\n",
    "benefits_df = summarize_cuped_benefits(df)\n",
    "print(\"\\nCUPED Benefits Summary:\")\n",
    "benefits_df\n",
    "```\n",
    "\n",
    "### 10.1 When to Use CUPED:\n",
    "\n",
    "1. High-variance metrics: Revenue, spending, engagement, and other metrics with high variance\n",
    "2. When you have reliable pre-experiment data that correlates with the post-experiment metric\n",
    "3. When your experiment duration or sample size is limited\n",
    "4. When you need to detect small but important effects\n",
    "\n",
    "### 10.2 When Not to Use CUPED:\n",
    "\n",
    "1. When pre-experiment data is not available or unreliable\n",
    "2. When there's weak correlation between pre and post metrics\n",
    "3. When there's potential data leakage or selection bias\n",
    "4. For new user experiments where pre-experiment data doesn't exist\n",
    "\n",
    "### 10.3 Implementation Checklist:\n",
    "\n",
    "1. Verify correlation between pre and post metrics\n",
    "2. Check for balance in pre-experiment metrics between treatment and control\n",
    "3. Ensure no data leakage (pre-experiment data shouldn't be affected by the treatment)\n",
    "4. Consider stratifying by important segments for even better results\n",
    "5. Use multiple covariates when appropriate\n",
    "6. Validate CUPED results against traditional methods\n",
    "7. Document the CUPED approach for transparency\n",
    "\n",
    "### 10.4 Final Thoughts\n",
    "\n",
    "CUPED is a powerful technique that can dramatically improve the efficiency of your experimentation program by:\n",
    "- Reducing false negatives (Type II errors)\n",
    "- Shortening experiment duration\n",
    "- Enabling detection of smaller effects\n",
    "\n",
    "When implemented correctly, CUPED allows for faster and more sensitive experimentation without increasing false positives, ultimately leading to better product decisions and accelerated innovation.\n",
    "\n",
    "print(\"\\nCUPED enables faster, more sensitive experiments without compromising statistical validity.\")\n",
    "print(\"By leveraging pre-experiment data, you can often reduce variance by 20-50%,\")\n",
    "print(\"which translates to 10-30% shorter experiment durations or smaller sample sizes.\")\n",
    "print(\"\\nImplement CUPED wisely, and happy experimenting!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b4f35a-6b87-4d95-b1af-3bf71c40bd61",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56aea22d-b495-4887-afb3-5dd7709a88e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
